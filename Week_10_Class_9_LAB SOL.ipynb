{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yJ6CPTGDfYo"
      },
      "source": [
        "# Week 10 - Class 9\n",
        "\n",
        "This notebook have the most important exercises for theoretical class 9, which covers chapter 8, and 9 from the book. The labs from https://github.com/fchollet/deep-learning-with-python-notebooks are a guide, mainly the labs 8,9. The topic in scope from Chapter 7 topics are also included in this lab.\n",
        "\n",
        "It will be covered:\n",
        "- Read image data (separate into folders, resize, normalize)\n",
        "- Image Classification\n",
        "- Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JC521xIrDfYp"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from os.path import isfile, join\n",
        "import os, shutil, pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31AxUZXjDfYq"
      },
      "source": [
        "# Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st1C9mlGL7be"
      },
      "source": [
        "Image dataset from here: https://www.kaggle.com/competitions/dogs-vs-cats/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2O5pOotDfYq"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOq3rfFXDfYq",
        "outputId": "ac3b62ed-9754-4eb4-bd23-fafbaefc26f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "dogs-vs-cats.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test1.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "#UPLOAD kaggle.json (IN GITHUB)\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip -qq dogs-vs-cats.zip\n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YX52YnFDfYq",
        "outputId": "babffcdf-340f-4bc7-b14b-96e8b358e36e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cats_vs_dogs_small/train/cat created\n",
            "cats_vs_dogs_small/train/dog created\n",
            "cats_vs_dogs_small/validation/cat created\n",
            "cats_vs_dogs_small/validation/dog created\n",
            "cats_vs_dogs_small/test/cat created\n",
            "cats_vs_dogs_small/test/dog created\n"
          ]
        }
      ],
      "source": [
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        try:\n",
        "          os.makedirs(dir)\n",
        "        except:\n",
        "          print(dir, 'created')\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gMH8DOiVFPkX"
      },
      "outputs": [],
      "source": [
        "# Find the average image size\n",
        "# all NN receive a fixed size (the real datasets have images with multiple sizes)\n",
        "path_cat=pathlib.Path('cats_vs_dogs_small/train/cat')\n",
        "path_dog=pathlib.Path('cats_vs_dogs_small/train/dog')\n",
        "\n",
        "onlyfiles_cat = [f for f in listdir(path_cat) if isfile(join(path_cat, f))]\n",
        "onlyfiles_dog = [f for f in listdir(path_dog) if isfile(join(path_dog, f))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LhsjnJadF-p6"
      },
      "outputs": [],
      "source": [
        "cats_size=[Image.open(join(path_cat, filename)).size for filename in onlyfiles_cat]\n",
        "dogs_size=[Image.open(join(path_dog, filename)).size for filename in onlyfiles_dog]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "PP60x3nTMDPR",
        "outputId": "ee85ad8f-a738-481a-c773-c939a260902f"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-4ed7c6a4b574>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cats_width=<your-answer>\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# PRINT THE MEAN, MIN, MAX, MEDIAN FOR THE IMAGES OF CATS AND DOGS\n",
        "\n",
        "cats_width=<your-answer>\n",
        "print(np.mean(cats_width), np.min(cats_width), np.max(cats_width), np.median(cats_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjAP8hcnMDH0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Y21C0iMDAR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG2WyrZkMVSI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVE0NuziMVOV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW7YjJ_qMVLF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkNdZdHqMVHB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnfP3dlkMVCH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXHICc45GU62"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "cats_width=[k[0] for k in cats_size]\n",
        "print(np.mean(cats_width), np.min(cats_width), np.max(cats_width), np.median(cats_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FY5SnDiHEnY"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "cats_height=[k[1] for k in cats_size]\n",
        "print(np.mean(cats_height), np.min(cats_height), np.max(cats_height), np.median(cats_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37BAPnZsHCDE"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "dogs_width=[k[0] for k in dogs_size]\n",
        "print(np.mean(dogs_width), np.min(dogs_width), np.max(dogs_width), np.median(dogs_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvAkE5kgHPPs"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "dogs_height=[k[1] for k in dogs_size]\n",
        "print(np.mean(dogs_height), np.min(dogs_height), np.max(dogs_height), np.median(dogs_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWfk4jywMYB1"
      },
      "outputs": [],
      "source": [
        "# How to do it with image_dataset_from_directory\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuPxpcWNMwMW"
      },
      "outputs": [],
      "source": [
        "# BUILD A DATASET\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random_numbers = np.random.normal(size=(1000, 16))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3jzrUC_M0kN"
      },
      "outputs": [],
      "source": [
        "#ACCESS DATASET SHAPE AND ELEMENTS\n",
        "for i, element in enumerate(dataset):\n",
        "    print(element.shape)\n",
        "    if i >= 2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8OINx-tOwSF"
      },
      "outputs": [],
      "source": [
        "# SEE THE SHAPE OF TRAIN DATASET ELEMENTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk-rlUYLO5A4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6p5XCwyO47r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VrJNMOYO43f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA44JuJGO4xW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hktK4TeeO5sc"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "for data_batch, labels_batch in train_dataset:\n",
        "    print(\"data batch shape:\", data_batch.shape)\n",
        "    print(\"labels batch shape:\", labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_5xGJLqSsns"
      },
      "source": [
        "The Keras **callbacks** API will help you transform your call to model.fit() \n",
        "\n",
        "A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to **fit()** and that is called by the model at various points\n",
        "during training. **It has access to all the available data about the state of the model and its performance, and it can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model.**\n",
        "\n",
        "Here are some examples of ways you can use callbacks:\n",
        "- *Model checkpointing* — Saving the current state of the model at different points during training.\n",
        "- *Early stopping* — Interrupting training when the validation loss is no longer improving (and of course, saving the best model obtained during training).\n",
        "- *Dynamically adjusting the value of certain parameters during training* — Such as the learning rate of the optimizer.\n",
        "- *Logging training and validation metrics during training, or visualizing the representations learned by the model as they’re updated* — The fit() progress bar that you’re\n",
        "familiar with is in fact a callback!\n",
        "\n",
        "The keras.callbacks module includes a number of built- in callbacks (this is not an exhaustive list):\n",
        "- keras.callbacks.ModelCheckpoint\n",
        "- keras.callbacks.EarlyStopping\n",
        "- keras.callbacks.LearningRateScheduler\n",
        "- keras.callbacks.ReduceLROnPlateau\n",
        "- keras.callbacks.CSVLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ2uTihTRgFj"
      },
      "outputs": [],
      "source": [
        "#MNIST Example\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#DEFINE THE MODEL: HEFE WE HAVE A FUNCTIONAL API MODEL\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "#DATA PROCESSING: RESHAPE, NORMALIZE, CREATE DATASETS\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]\n",
        "\n",
        "model = get_mnist_model()\n",
        "#DEFINE METRICS\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "#TRAIN\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "#EVALUATE\n",
        "test_metrics = model.evaluate(test_images, test_labels)\n",
        "#PREDICT\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlYVTsV5UBV2"
      },
      "outputs": [],
      "source": [
        "# USING CALLBACKS\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=2,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"checkpoint_path.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf_6sTmUDfYq"
      },
      "outputs": [],
      "source": [
        "#BUILD A MODEL FOR THE CATS AND DOGS DATASET WITH:\n",
        "#HEIGHT AND WIDTH IS 180 PIXELS\n",
        "#ALL KERNELS HAVE A SIZE OF 3\n",
        "#ALL ACTIVATION FUNCTIONS ARE \"relu\" except the last one which is \"sigmoid\"\n",
        "\n",
        "#input layer, check the input size\n",
        "\n",
        "#normalization layer (tip: how do you normalize rgb images?)\n",
        "\n",
        "#block A\n",
        "# 2D convolution layer with 32 filters\n",
        "\n",
        "#maxpooling layer with a size of 2\n",
        "\n",
        "#block B\n",
        "# 2D convolution layer with 64 filters\n",
        "\n",
        "#maxpooling layer with a size of 2\n",
        "\n",
        "#block C\n",
        "# 2D convolution layer with 128 filters\n",
        "\n",
        "#maxpooling layer with a size of 2\n",
        "\n",
        "#block D\n",
        "# 2D convolution layer with 256 filters\n",
        "\n",
        "#maxpooling layer with a size of 2\n",
        "\n",
        "#block D\n",
        "# 2D convolution layer with 256 filters\n",
        "\n",
        "#data transformation layer\n",
        "\n",
        "#fully connected layer with X outputs (X is the number of classes the CNN is predicting)\n",
        "\n",
        "#attach previous sequence of layers to keras.Model class\n",
        "\n",
        "# compile the model with the optimizer='rmsprop'; choose the loss and metrics accordingly \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj2PXWhgaHzJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCu4-hlwaHwP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwKLVDSwaHtA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QDJj69VaHpn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOQ2cEFiaHmb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrsHu6agaHjG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPPwP2f-aHfq"
      },
      "outputs": [],
      "source": [
        "#sol\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rVxJNiwDfYq"
      },
      "outputs": [],
      "source": [
        "#CALLBACKS\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\"),\n",
        "\n",
        "        keras.callbacks.TensorBoard(\n",
        "    log_dir=\"/LOG\",\n",
        ")\n",
        "]\n",
        "\n",
        "#data aug\n",
        "#pre trained\n",
        "# number of parameters (slide from classes)\n",
        "#x ception example\n",
        "#put link for visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asxk-zBjcxTt"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=5,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJz3lUsmfE7y"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /LOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9B3iNktfAJl"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMkowLIQdFPM"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrNdvApxaayF"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeJcgh5kb8B1"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMIyvYpWDfYr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr444ze2DfYr"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peigzpRFDfYs"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sQRVhRmDfYs"
      },
      "source": [
        "1.7 Why are we doing data augmentation? Connect your answer with the validation and training loss trends through epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tveRW4DJDfYs"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYBLfJb0DfYs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[2].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2QgYBQxDfYs"
      },
      "source": [
        "## Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_-xkBdPDfYs"
      },
      "source": [
        "\n",
        "Defining a new convnet that includes image augmentation and dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs87FgwmDfYs"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqXUcVqADfYs"
      },
      "outputs": [],
      "source": [
        "#with 15min of training (100 epochs), data augmentation and dropout \n",
        "# went from 70% to 77% in val acc (without adding data!)\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKe3avD5DfYs"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ17dvQPDfYt"
      },
      "source": [
        "# Transfer Learning with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs1lEoMBDfYt"
      },
      "outputs": [],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYio5F8BDfYt"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYa4M_1KDfYt"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5p9lrx4DfYt"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x) #the data passes 1 time through the weight\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOOZ2UaXDfYt"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD_zpxoSDfYt"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSq1nmoEDfYt"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaGdEyKZDfYt"
      },
      "source": [
        "2.0 What is the difference between transfer learning and fine tuning?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giL6jzvLDfYt"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmxdTAMCDfYt"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldWuycaPDfYt"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"fine_tuning.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AY9JdJBDfYu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hrimWzkDfYu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d33a1388bb95f6f47390937b44de6829ea073fadb3ed2a95296fdc5e4fdfba80"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
