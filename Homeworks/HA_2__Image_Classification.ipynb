{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2: Image Classification with Xception (keras)\n",
        "In this assignment you will scrape data from google image search on swiss politicians for the last 10 years. \n",
        "\n",
        "You will build from scratch a Xception CNN model (state of the art image classification model) to classify the party based on its politicians photographs. \n",
        "\n",
        "You will apply what you've learned at class 8 and lab 9. You need to read the Xception paper (https://arxiv.org/pdf/1610.02357.pdf) and re use a slightly modified version of this code (https://towardsdatascience.com/xception-from-scratch-using-tensorflow-even-better-than-inception-940fb231ced9 )"
      ],
      "metadata": {
        "id": "AOLgS8yzim6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "DJ7iqYAVa46O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UPMF3Ruv5b9"
      },
      "outputs": [],
      "source": [
        "politicians = {\n",
        "    'SP': ['Christian Levrat', 'Simonetta Sommaruga', 'Alain Berset'],\n",
        "    'SVP': ['Ueli Maurer', 'Christoph Blocher', 'Guy Parmelin'],\n",
        "    'FDP': ['Ignazio Cassis', 'Johann Schneider-Ammann', 'Didier Burkhalter'],\n",
        "    'CVP': ['Doris Leuthard', 'Viola Amherd', 'Gerhard Pfister'],\n",
        "    'GLP': ['Martin Bäumle', 'Tiana Angelina Moser', 'Jürg Grossen']\n",
        "}\n",
        "k=0\n",
        "for party, politicians_list in politicians.items():\n",
        "    k=0\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    for i, politician in enumerate(politicians_list):\n",
        "        query = f\"{politician} {party} schweiz\"\n",
        "        url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        img_tags = soup.find_all(\"img\")\n",
        "        \n",
        "        for j, img_tag in enumerate(img_tags):\n",
        "            image_url = img_tag[\"src\"]\n",
        "            if \"http\" not in image_url:\n",
        "                continue\n",
        "            try:\n",
        "                img_data = requests.get(image_url).content\n",
        "                img = Image.open(BytesIO(img_data))\n",
        "                img = img.convert(\"RGB\")\n",
        "                img.save(f\"data/{party}_{k}.jpg\")\n",
        "                #print(f\"Saved image {k} for {politician} from {party} party\")\n",
        "                k+=1\n",
        "            except OSError:\n",
        "                img = img.convert(\"RGB\")\n",
        "                img.save(f\"data/{party}_{k}.jpg\")\n",
        "                #print(f\"Saved image {k} for {politician} from {party} party (converted RGBA to RGB)\")\n",
        "                k+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 (15 Points)\n",
        "\n",
        "a) Create a keras dataset object (image_dataset_from_directory) for training, testing and validating dataset. \n",
        "\n",
        "b) Check the basic statistics for image dimension and choose a input size accordingly (this will be contrained by the model you choose. In this lab, the architecture of the model is pre defined by its author.)"
      ],
      "metadata": {
        "id": "-5h32qtzdRJf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PjF2kwuqeB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8G5LqWZ9qd9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 and 3 (30 Points)\n",
        "\n",
        "a) Add data augmentation step to your code\n",
        "\n",
        "b) Explain why you choose those transformation from the available ones"
      ],
      "metadata": {
        "id": "VMImzO8Zd6NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer b):\n",
        "\n"
      ],
      "metadata": {
        "id": "IBtio0k7eIw-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nA3sl-6kqfWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zopoJPT-qfNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 (15 Points)\n",
        "\n",
        "Code explicitly (layer by layer) a mini Xception neural network "
      ],
      "metadata": {
        "id": "_jNtCKX4eOBk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcAKIRXVqgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnzgP08wqgOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5 (15 Points)\n",
        "\n",
        "a) Print the model summary in table and graph format. \n",
        "\n",
        "b) When saving the checkpoint of the model after training in a .keras file (or .h5) file, we say we are 'saving the model'. What does that means? How many parameters are we saving in that file for this type of NN?"
      ],
      "metadata": {
        "id": "kiJ_t2SIg7Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGmU8--vqhu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1cGfihuCqhrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6 (15 Points)\n",
        "\n",
        "Plot Training and validation accuracy in one plot, with different color or patterns for each stream of values"
      ],
      "metadata": {
        "id": "b9pDbIjBgYN4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S50JN8qSqj-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B166zK1iqj45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7 (15 Points)\n",
        "\n",
        "Based on the reading of the paper and class 8 slides: \n",
        "\n",
        "a) Does the Xception NN has residual connections? What are those and which problem within deep learning do they try to solve?\n",
        "\n",
        "b) what are residual Depthwise Seperable Convolutions? "
      ],
      "metadata": {
        "id": "36ni0dBJi_wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deliver"
      ],
      "metadata": {
        "id": "CqzAK4U4dIb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HOW TO DELIVER: https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab\n",
        "#download this notebook after all your answers and upload it to the files tab on the left\n",
        "#right click on it to check the path \n",
        "#replace the path ('/content/Untitled0.ipynb') by your file path\n",
        "%%shell\n",
        "jupyter nbconvert --to html /content/Untitled0.ipynb\n",
        "\n",
        "#refresh the folder (not the page)\n",
        "#download the html\n",
        "     "
      ],
      "metadata": {
        "id": "sXTpI91Rcj5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}